{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc1b5f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import logging\n",
    "import tempfile\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, Audio, HTML\n",
    "import torch\n",
    "import torchaudio\n",
    "from transformers import pipeline\n",
    "from groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16414a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3880b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechGenerator:\n",
    "    \"\"\"Class for generating and managing AI-generated speeches.\"\"\"\n",
    "    \n",
    "    # Define speech style templates and audience guidance as class attributes\n",
    "    STYLE_TEMPLATES = {\n",
    "        \"formal\": \"Write a formal {duration}-minute speech about '{topic}' suitable for a professional audience.\",\n",
    "        \"casual\": \"Write a casual, friendly {duration}-minute speech about '{topic}'.\",\n",
    "        \"motivational\": \"Write an inspiring {duration}-minute motivational speech about '{topic}' that energizes the audience.\",\n",
    "        \"persuasive\": \"Write a compelling {duration}-minute persuasive speech about '{topic}' to change minds.\",\n",
    "        \"instructional\": \"Write a step-by-step {duration}-minute instructional speech on '{topic}'.\",\n",
    "        \"debate\": \"Write a {duration}-minute debate speech about '{topic}' with strong arguments and counterpoints.\",\n",
    "        \"humorous\": \"Write a funny {duration}-minute speech about '{topic}' with appropriate humor and wit.\",\n",
    "        \"storytelling\": \"Write an engaging {duration}-minute speech about '{topic}' using storytelling techniques.\",\n",
    "    }\n",
    "    \n",
    "    AUDIENCE_GUIDANCE = {\n",
    "        \"general\": \"Make the speech accessible to a general audience with no specialized knowledge.\",\n",
    "        \"experts\": \"Include technical depth suitable for experts in the field.\",\n",
    "        \"children\": \"Use simple, engaging language and examples suitable for kids.\",\n",
    "        \"students\": \"Be educational and engaging for a student audience.\",\n",
    "        \"executives\": \"Focus on strategic implications and leadership perspectives.\",\n",
    "        \"international\": \"Use globally accessible references and minimize culturally specific idioms.\",\n",
    "    }\n",
    "    \n",
    "    # LLM models available for speech generation\n",
    "    AVAILABLE_MODELS = {\n",
    "        \"llama3-8b-8192\": {\"description\": \"Balanced model for general use\", \"max_tokens\": 8192},\n",
    "        \"llama3-70b-8192\": {\"description\": \"Advanced model with better quality\", \"max_tokens\": 8192},\n",
    "        \"gemma-7b-it\": {\"description\": \"Efficient model for simpler tasks\", \"max_tokens\": 4096}\n",
    "    }\n",
    "    \n",
    "    # TTS voice options with their characteristics\n",
    "    TTS_VOICES = {\n",
    "        \"en_male_neutral\": {\"gender\": \"male\", \"style\": \"neutral\", \"description\": \"Clear, professional male voice\"},\n",
    "        \"en_female_neutral\": {\"gender\": \"female\", \"style\": \"neutral\", \"description\": \"Clear, professional female voice\"},\n",
    "        \"en_male_enthusiastic\": {\"gender\": \"male\", \"style\": \"enthusiastic\", \"description\": \"Energetic male voice for motivational content\"},\n",
    "        \"en_female_enthusiastic\": {\"gender\": \"female\", \"style\": \"enthusiastic\", \"description\": \"Energetic female voice for motivational content\"},\n",
    "        \"en_male_formal\": {\"gender\": \"male\", \"style\": \"formal\", \"description\": \"Formal, authoritative male voice\"},\n",
    "        \"en_female_formal\": {\"gender\": \"female\", \"style\": \"formal\", \"description\": \"Formal, authoritative female voice\"},\n",
    "    }\n",
    "    \n",
    "    def __init__(self, api_key_path: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Initialize the SpeechGenerator with optional API key from file.\n",
    "        \n",
    "        Args:\n",
    "            api_key_path: Path to a JSON file containing the Groq API key.\n",
    "        \"\"\"\n",
    "        self.api_key = None\n",
    "        self.client = None\n",
    "        self.output_folder = \"speech_outputs\"\n",
    "        self.audio_folder = os.path.join(self.output_folder, \"audio\")\n",
    "        self.history = []\n",
    "        self.tts_engine = None\n",
    "        \n",
    "        # Create output folders if they don't exist\n",
    "        for folder in [self.output_folder, self.audio_folder]:\n",
    "            if not os.path.exists(folder):\n",
    "                os.makedirs(folder)\n",
    "        \n",
    "        # Initialize text-to-speech engine\n",
    "        self._initialize_tts_engine()\n",
    "                \n",
    "        # Load API key if provided\n",
    "        if api_key_path:\n",
    "            self.load_api_key(api_key_path)\n",
    "    \n",
    "    def _initialize_tts_engine(self):\n",
    "        \"\"\"Initialize the text-to-speech engine using transformers.\"\"\"\n",
    "        try:\n",
    "            # Check if CUDA (GPU) is available\n",
    "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "            \n",
    "            # Initialize the TTS pipeline\n",
    "            self.tts_engine = pipeline(\n",
    "                \"text-to-speech\", \n",
    "                model=\"microsoft/speecht5_tts\", \n",
    "                device=device\n",
    "            )\n",
    "            \n",
    "            # Load vocoder for better audio quality\n",
    "            self.vocoder = pipeline(\n",
    "                \"text-to-speech\",\n",
    "                model=\"microsoft/speecht5_hifigan\",\n",
    "                device=device\n",
    "            )\n",
    "            \n",
    "            logger.info(f\"TTS engine initialized on {device}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to initialize TTS engine: {str(e)}\")\n",
    "            self.tts_engine = None\n",
    "    \n",
    "    def load_api_key(self, api_key_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Load API key from a JSON file.\n",
    "        \n",
    "        Args:\n",
    "            api_key_path: Path to a JSON file containing the Groq API key.\n",
    "        \n",
    "        Raises:\n",
    "            FileNotFoundError: If the API key file doesn't exist.\n",
    "            KeyError: If the API key is not in the expected format.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(api_key_path, 'r') as f:\n",
    "                config = json.load(f)\n",
    "                self.api_key = config.get('groq_api_key')\n",
    "                if not self.api_key:\n",
    "                    raise KeyError(\"API key not found in config file.\")\n",
    "                self.initialize_client()\n",
    "                logger.info(\"API key loaded successfully.\")\n",
    "        except FileNotFoundError:\n",
    "            logger.error(f\"API key file not found at {api_key_path}\")\n",
    "            raise\n",
    "        except json.JSONDecodeError:\n",
    "            logger.error(f\"Invalid JSON format in {api_key_path}\")\n",
    "            raise\n",
    "    \n",
    "    def set_api_key(self, api_key: str) -> None:\n",
    "        \"\"\"\n",
    "        Set the API key directly.\n",
    "        \n",
    "        Args:\n",
    "            api_key: Groq API key.\n",
    "        \"\"\"\n",
    "        self.api_key = api_key\n",
    "        self.initialize_client()\n",
    "        logger.info(\"API key set successfully.\")\n",
    "    \n",
    "    def initialize_client(self) -> None:\n",
    "        \"\"\"Initialize the Groq client with the loaded API key.\"\"\"\n",
    "        if self.api_key:\n",
    "            self.client = Groq(api_key=self.api_key)\n",
    "            logger.info(\"Groq client initialized.\")\n",
    "        else:\n",
    "            logger.warning(\"No API key available. Set API key before generating speeches.\")\n",
    "    \n",
    "    def build_prompt(self, topic: str, duration: int, emotion: str = \"formal\", \n",
    "                   audience: str = \"general\", additional_instructions: str = \"\") -> str:\n",
    "        \"\"\"\n",
    "        Build a detailed prompt for Groq-based speech generation.\n",
    "        \n",
    "        Args:\n",
    "            topic: The speech topic.\n",
    "            duration: Speech duration in minutes.\n",
    "            emotion: Style of the speech.\n",
    "            audience: Target audience.\n",
    "            additional_instructions: Any additional instructions for the model.\n",
    "            \n",
    "        Returns:\n",
    "            str: Generated prompt for the LLM.\n",
    "        \"\"\"\n",
    "        base_prompt = self.STYLE_TEMPLATES.get(emotion, self.STYLE_TEMPLATES[\"formal\"]).format(\n",
    "            topic=topic, duration=duration\n",
    "        )\n",
    "        audience_note = self.AUDIENCE_GUIDANCE.get(audience, self.AUDIENCE_GUIDANCE[\"general\"])\n",
    "        \n",
    "        # Calculate approximate word count (130 words per minute is average speech rate)\n",
    "        word_count = duration * 130\n",
    "        \n",
    "        final_prompt = (\n",
    "            f\"{base_prompt}\\n\\n\"\n",
    "            f\"{audience_note}\\n\\n\"\n",
    "            f\"Structure the speech with an introduction, body, and conclusion.\\n\"\n",
    "            f\"Use engaging transitions, rhetorical devices, and paragraph breaks.\\n\"\n",
    "            f\"Include natural pauses (marked with [pause]) and emphasis points (marked with *emphasis*) to guide the delivery.\\n\"\n",
    "            f\"Add occasional delivery notes in [brackets] for pacing, tone, or gestures.\\n\"\n",
    "            f\"Aim for approximately {word_count} words to fill {duration} minutes when delivered aloud.\\n\"\n",
    "        )\n",
    "        \n",
    "        if additional_instructions:\n",
    "            final_prompt += f\"\\nAdditional instructions: {additional_instructions}\\n\"\n",
    "        \n",
    "        return final_prompt\n",
    "    \n",
    "    def generate_speech(self, topic: str, duration: int, emotion: str, audience: str, \n",
    "                        model: str = \"llama3-8b-8192\", temperature: float = 0.7, \n",
    "                        additional_instructions: str = \"\") -> Tuple[str, Dict]:\n",
    "        \"\"\"\n",
    "        Generate a speech using the Groq API.\n",
    "        \n",
    "        Args:\n",
    "            topic: The speech topic.\n",
    "            duration: Speech duration in minutes.\n",
    "            emotion: Style of the speech.\n",
    "            audience: Target audience.\n",
    "            model: The LLM model to use.\n",
    "            temperature: Creativity parameter (0.0 to 1.0).\n",
    "            additional_instructions: Additional guidance for the model.\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[str, Dict]: The generated speech text and metadata.\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If API key is not set.\n",
    "        \"\"\"\n",
    "        if not self.client:\n",
    "            raise ValueError(\"API key not set. Use set_api_key() or load_api_key() first.\")\n",
    "        \n",
    "        # Build prompt based on input\n",
    "        prompt = self.build_prompt(topic, duration, emotion, audience, additional_instructions)\n",
    "        \n",
    "        # Generation metadata\n",
    "        metadata = {\n",
    "            \"topic\": topic,\n",
    "            \"duration\": duration,\n",
    "            \"emotion\": emotion,\n",
    "            \"audience\": audience,\n",
    "            \"model\": model,\n",
    "            \"temperature\": temperature,\n",
    "            \"timestamp\": None,  # Will be added after generation\n",
    "            \"word_count\": 0,    # Will be updated after generation\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Set max tokens based on the model or default to a safe value\n",
    "            max_tokens = self.AVAILABLE_MODELS.get(model, {}).get(\"max_tokens\", 2048)\n",
    "            \n",
    "            # Groq API call\n",
    "            completion = self.client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=temperature,\n",
    "                max_tokens=min(max_tokens, 4096),  # Ensure we don't exceed model limits\n",
    "                top_p=1,\n",
    "                stream=True\n",
    "            )\n",
    "            \n",
    "            # Collect and display streaming output\n",
    "            speech = \"\"\n",
    "            for chunk in completion:\n",
    "                chunk_content = chunk.choices[0].delta.content or \"\"\n",
    "                speech += chunk_content\n",
    "                # For UI updates if needed - implement later\n",
    "            \n",
    "            # Update metadata\n",
    "            import datetime\n",
    "            metadata[\"timestamp\"] = datetime.datetime.now().isoformat()\n",
    "            metadata[\"word_count\"] = len(speech.split())\n",
    "            \n",
    "            # Add to history\n",
    "            self.history.append(metadata)\n",
    "            \n",
    "            return speech, metadata\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"API error: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def save_speech(self, speech_text: str, metadata: Dict) -> str:\n",
    "        \"\"\"\n",
    "        Save the generated speech to a file.\n",
    "        \n",
    "        Args:\n",
    "            speech_text: The generated speech content.\n",
    "            metadata: Speech metadata for filename generation.\n",
    "            \n",
    "        Returns:\n",
    "            str: Path to the saved file.\n",
    "        \"\"\"\n",
    "        # Generate filename from topic\n",
    "        topic_clean = self._sanitize_filename(metadata[\"topic\"])\n",
    "        audience_clean = self._sanitize_filename(metadata[\"audience\"])\n",
    "        emotion_clean = self._sanitize_filename(metadata[\"emotion\"])\n",
    "        \n",
    "        base_filename = f\"speech_{topic_clean}_{emotion_clean}_{audience_clean}\"\n",
    "        filename = f\"{base_filename}.txt\"\n",
    "        file_path = os.path.join(self.output_folder, filename)\n",
    "        \n",
    "        # Ensure uniqueness\n",
    "        counter = 1\n",
    "        while os.path.exists(file_path):\n",
    "            filename = f\"{base_filename}_{counter}.txt\"\n",
    "            file_path = os.path.join(self.output_folder, filename)\n",
    "            counter += 1\n",
    "        \n",
    "        # Save speech with metadata\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"# {metadata['topic']}\\n\")\n",
    "            f.write(f\"# Duration: {metadata['duration']} min | Style: {metadata['emotion']} | Audience: {metadata['audience']}\\n\")\n",
    "            f.write(f\"# Generated on: {metadata['timestamp']} using {metadata['model']}\\n\\n\")\n",
    "            f.write(speech_text)\n",
    "        \n",
    "        logger.info(f\"Speech saved to {file_path}\")\n",
    "        return file_path\n",
    "    \n",
    "    def prepare_text_for_tts(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Prepare the text for text-to-speech by removing or converting special markers.\n",
    "        \n",
    "        Args:\n",
    "            text: The speech text with special markers.\n",
    "            \n",
    "        Returns:\n",
    "            str: Clean text suitable for TTS processing.\n",
    "        \"\"\"\n",
    "        # Remove delivery notes in brackets\n",
    "        text = re.sub(r'\\[.*?\\]', '', text)\n",
    "        \n",
    "        # Remove emphasis markers (asterisks) but keep the text\n",
    "        text = re.sub(r'\\*(.*?)\\*', r'\\1', text)\n",
    "        \n",
    "        # Add periods after paragraph breaks to create natural pauses\n",
    "        text = re.sub(r'\\n\\n', '.\\n\\n', text)\n",
    "        \n",
    "        # Break into sentences for better TTS chunking\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "        \n",
    "        return sentences\n",
    "    \n",
    "    def generate_speech_audio(self, text: str, voice: str = \"en_female_neutral\", \n",
    "                             output_filename: Optional[str] = None) -> str:\n",
    "        \"\"\"\n",
    "        Generate audio for the speech text using the TTS engine.\n",
    "        \n",
    "        Args:\n",
    "            text: The speech text.\n",
    "            voice: Voice ID to use.\n",
    "            output_filename: Optional custom filename for the audio.\n",
    "            \n",
    "        Returns:\n",
    "            str: Path to the generated audio file.\n",
    "        \"\"\"\n",
    "        if not self.tts_engine:\n",
    "            raise ValueError(\"TTS engine not available. Check logs for initialization errors.\")\n",
    "        \n",
    "        # Prepare text by cleaning and chunking\n",
    "        text_chunks = self.prepare_text_for_tts(text)\n",
    "        \n",
    "        # Generate a default filename if not provided\n",
    "        if not output_filename:\n",
    "            timestamp = int(time.time())\n",
    "            output_filename = f\"speech_audio_{timestamp}.wav\"\n",
    "        \n",
    "        output_path = os.path.join(self.audio_folder, output_filename)\n",
    "        \n",
    "        try:\n",
    "            # Process in chunks to avoid TTS limits and create better pacing\n",
    "            combined_audio = []\n",
    "            \n",
    "            # Select voice parameters based on the requested voice\n",
    "            voice_info = self.TTS_VOICES.get(voice, self.TTS_VOICES[\"en_female_neutral\"])\n",
    "            \n",
    "            logger.info(f\"Generating audio using {voice_info['description']}\")\n",
    "            \n",
    "            # Process text in manageable chunks\n",
    "            for i, chunk in enumerate(text_chunks):\n",
    "                if not chunk.strip():  # Skip empty chunks\n",
    "                    continue\n",
    "                    \n",
    "                # Generate speech for this chunk\n",
    "                speaker_embedding = None  # In a real implementation, this would be voice-specific\n",
    "                \n",
    "                speech = self.tts_engine(\n",
    "                    text=chunk,\n",
    "                    speaker_embeddings=speaker_embedding,\n",
    "                    return_tensors=True\n",
    "                )\n",
    "                \n",
    "                # Generate audio with the vocoder for better quality\n",
    "                audio = self.vocoder(speech[\"generated_speech\"])\n",
    "                \n",
    "                # Add a small pause between chunks\n",
    "                if i < len(text_chunks) - 1:\n",
    "                    # Add 0.5s silence\n",
    "                    sample_rate = audio[\"sampling_rate\"]\n",
    "                    silence = torch.zeros(int(0.5 * sample_rate))\n",
    "                    audio[\"audio\"] = torch.cat([audio[\"audio\"], silence])\n",
    "                \n",
    "                combined_audio.append(audio[\"audio\"])\n",
    "            \n",
    "            # Combine all audio chunks\n",
    "            full_audio = torch.cat(combined_audio)\n",
    "            sample_rate = audio[\"sampling_rate\"]\n",
    "            \n",
    "            # Save the combined audio\n",
    "            torchaudio.save(output_path, full_audio.unsqueeze(0), sample_rate)\n",
    "            \n",
    "            logger.info(f\"Audio saved to {output_path}\")\n",
    "            return output_path\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating audio: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def get_speech_history(self) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Get the history of generated speeches.\n",
    "        \n",
    "        Returns:\n",
    "            List[Dict]: List of metadata for all generated speeches.\n",
    "        \"\"\"\n",
    "        return self.history\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sanitize_filename(text: str) -> str:\n",
    "        \"\"\"\n",
    "        Convert text to a safe filename.\n",
    "        \n",
    "        Args:\n",
    "            text: Text to sanitize.\n",
    "            \n",
    "        Returns:\n",
    "            str: Sanitized text suitable for filenames.\n",
    "        \"\"\"\n",
    "        # Replace spaces with underscores and remove special characters\n",
    "        return re.sub(r'[^a-zA-Z0-9_]', '', text.replace(\" \", \"_\"))[:30]  # Limit length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2460500",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechGeneratorUI:\n",
    "    \"\"\"Class for the Jupyter notebook UI for speech generation.\"\"\"\n",
    "    \n",
    "    def __init__(self, generator: SpeechGenerator):\n",
    "        \"\"\"\n",
    "        Initialize the UI with a SpeechGenerator instance.\n",
    "        \n",
    "        Args:\n",
    "            generator: SpeechGenerator instance.\n",
    "        \"\"\"\n",
    "        self.generator = generator\n",
    "        self.speech_text = None\n",
    "        self.speech_metadata = None\n",
    "        self.audio_path = None\n",
    "        self.create_widgets()\n",
    "        \n",
    "    def create_widgets(self) -> None:\n",
    "        \"\"\"Create and display the input widgets.\"\"\"\n",
    "        # API Key widget\n",
    "        self.api_key_input = widgets.Password(\n",
    "            description=\"API Key:\", \n",
    "            placeholder=\"Enter Groq API key\",\n",
    "            layout=widgets.Layout(width='50%')\n",
    "        )\n",
    "        self.api_key_button = widgets.Button(description=\"Set API Key\")\n",
    "        self.api_key_button.on_click(self._on_api_key_button_click)\n",
    "        \n",
    "        # Input widgets\n",
    "        self.topic_input = widgets.Text(\n",
    "            value=\"Recent Trends in AI\", \n",
    "            description=\"Topic:\",\n",
    "            layout=widgets.Layout(width='80%')\n",
    "        )\n",
    "        \n",
    "        self.emotion_dropdown = widgets.Dropdown(\n",
    "            options=list(self.generator.STYLE_TEMPLATES.keys()),\n",
    "            value=\"instructional\", \n",
    "            description=\"Style:\"\n",
    "        )\n",
    "        \n",
    "        self.duration_slider = widgets.IntSlider(\n",
    "            value=3, min=1, max=15, step=1, \n",
    "            description=\"Duration (min):\"\n",
    "        )\n",
    "        \n",
    "        self.audience_dropdown = widgets.Dropdown(\n",
    "            options=list(self.generator.AUDIENCE_GUIDANCE.keys()),\n",
    "            value=\"students\", \n",
    "            description=\"Audience:\"\n",
    "        )\n",
    "        \n",
    "        self.model_dropdown = widgets.Dropdown(\n",
    "            options=list(self.generator.AVAILABLE_MODELS.keys()),\n",
    "            value=\"llama3-8b-8192\", \n",
    "            description=\"Model:\"\n",
    "        )\n",
    "        \n",
    "        self.temperature_slider = widgets.FloatSlider(\n",
    "            value=0.7, min=0.1, max=1.0, step=0.1,\n",
    "            description=\"Temperature:\"\n",
    "        )\n",
    "        \n",
    "        self.additional_instructions = widgets.Textarea(\n",
    "            value=\"\", \n",
    "            placeholder=\"Enter any additional instructions here...\",\n",
    "            description=\"Additional:\",\n",
    "            layout=widgets.Layout(width='80%', height='80px')\n",
    "        )\n",
    "        \n",
    "        # TTS voice selection\n",
    "        self.voice_dropdown = widgets.Dropdown(\n",
    "            options=[(f\"{v['gender'].capitalize()} {v['style'].capitalize()}\", k) for k, v in self.generator.TTS_VOICES.items()],\n",
    "            value=\"en_female_neutral\", \n",
    "            description=\"Voice:\"\n",
    "        )\n",
    "        \n",
    "        # Action buttons\n",
    "        self.generate_button = widgets.Button(\n",
    "            description=\"Generate Speech\",\n",
    "            button_style='primary'\n",
    "        )\n",
    "        self.generate_button.on_click(self._on_generate_button_click)\n",
    "        \n",
    "        self.save_button = widgets.Button(\n",
    "            description=\"Save Text\",\n",
    "            button_style='success',\n",
    "            disabled=True\n",
    "        )\n",
    "        self.save_button.on_click(self._on_save_button_click)\n",
    "        \n",
    "        self.audio_button = widgets.Button(\n",
    "            description=\"Generate Audio\",\n",
    "            button_style='info',\n",
    "            disabled=True\n",
    "        )\n",
    "        self.audio_button.on_click(self._on_audio_button_click)\n",
    "        \n",
    "        self.clear_button = widgets.Button(\n",
    "            description=\"Clear Output\",\n",
    "            button_style='warning'\n",
    "        )\n",
    "        self.clear_button.on_click(self._on_clear_button_click)\n",
    "        \n",
    "        # Output areas\n",
    "        self.output = widgets.Output()\n",
    "        self.status_output = widgets.Output()\n",
    "        self.audio_output = widgets.Output()\n",
    "        \n",
    "        # Display widgets\n",
    "        display(widgets.HTML(\"<h2>🎤 AI Speech Generator with Audio</h2>\"))\n",
    "        display(widgets.HBox([self.api_key_input, self.api_key_button]))\n",
    "        \n",
    "        # Model selection area\n",
    "        model_box = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>Model Settings</h3>\"),\n",
    "            widgets.HBox([self.model_dropdown, self.temperature_slider])\n",
    "        ])\n",
    "        \n",
    "        # Content settings area\n",
    "        content_box = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>Speech Content</h3>\"),\n",
    "            self.topic_input,\n",
    "            widgets.HBox([self.emotion_dropdown, self.audience_dropdown, self.duration_slider]),\n",
    "            self.additional_instructions\n",
    "        ])\n",
    "        \n",
    "        # Audio settings\n",
    "        audio_box = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>Audio Settings</h3>\"),\n",
    "            self.voice_dropdown\n",
    "        ])\n",
    "        \n",
    "        # Button area\n",
    "        button_box = widgets.HBox([\n",
    "            self.generate_button, self.save_button, self.audio_button, self.clear_button\n",
    "        ])\n",
    "        \n",
    "        display(model_box, content_box, audio_box, button_box, self.status_output, self.output, self.audio_output)\n",
    "        \n",
    "        with self.status_output:\n",
    "            print(\"Ready to generate speeches. Please set your API key to begin.\")\n",
    "    \n",
    "    def _on_api_key_button_click(self, button):\n",
    "        \"\"\"Handle API key button click.\"\"\"\n",
    "        with self.status_output:\n",
    "            clear_output()\n",
    "            try:\n",
    "                self.generator.set_api_key(self.api_key_input.value)\n",
    "                print(\"✅ API key set successfully. Ready to generate speeches.\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error setting API key: {str(e)}\")\n",
    "    \n",
    "    def _on_generate_button_click(self, button):\n",
    "        \"\"\"Handle generate button click.\"\"\"\n",
    "        with self.status_output:\n",
    "            clear_output()\n",
    "            print(\"🔄 Generating speech... Please wait.\")\n",
    "        \n",
    "        with self.output:\n",
    "            clear_output()\n",
    "            try:\n",
    "                # Generate speech\n",
    "                speech_text, metadata = self.generator.generate_speech(\n",
    "                    topic=self.topic_input.value,\n",
    "                    duration=self.duration_slider.value,\n",
    "                    emotion=self.emotion_dropdown.value,\n",
    "                    audience=self.audience_dropdown.value,\n",
    "                    model=self.model_dropdown.value,\n",
    "                    temperature=self.temperature_slider.value,\n",
    "                    additional_instructions=self.additional_instructions.value\n",
    "                )\n",
    "                \n",
    "                # Store the speech text and metadata for saving later\n",
    "                self.speech_text = speech_text\n",
    "                self.speech_metadata = metadata\n",
    "                \n",
    "                # Enable save and audio buttons\n",
    "                self.save_button.disabled = False\n",
    "                self.audio_button.disabled = False\n",
    "                \n",
    "                # Display speech text with metadata\n",
    "                print(f\"# {metadata['topic']}\")\n",
    "                print(f\"# Style: {metadata['emotion']} | Audience: {metadata['audience']} | Duration: {metadata['duration']} min\")\n",
    "                print(f\"# Word count: {metadata['word_count']} words\\n\")\n",
    "                print(speech_text)\n",
    "                \n",
    "                # Update status\n",
    "                with self.status_output:\n",
    "                    clear_output()\n",
    "                    print(f\"✅ Speech generated successfully with {metadata['word_count']} words (~{metadata['duration']} min).\")\n",
    "                    print(\"Use the 'Save Text' button to save the text or 'Generate Audio' to create an audio version.\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                with self.status_output:\n",
    "                    clear_output()\n",
    "                    print(f\"❌ Error generating speech: {str(e)}\")\n",
    "    \n",
    "    def _on_save_button_click(self, button):\n",
    "        \"\"\"Handle save button click.\"\"\"\n",
    "        try:\n",
    "            if hasattr(self, 'speech_text') and self.speech_text is not None:\n",
    "                file_path = self.generator.save_speech(self.speech_text, self.speech_metadata)\n",
    "                with self.status_output:\n",
    "                    clear_output()\n",
    "                    print(f\"💾 Speech text saved to: {file_path}\")\n",
    "            else:\n",
    "                with self.status_output:\n",
    "                    clear_output()\n",
    "                    print(\"❌ No speech generated yet to save.\")\n",
    "        except Exception as e:\n",
    "            with self.status_output:\n",
    "                clear_output()\n",
    "                print(f\"❌ Error saving speech: {str(e)}\")\n",
    "    \n",
    "    def _on_audio_button_click(self, button):\n",
    "        \"\"\"Handle audio generation button click.\"\"\"\n",
    "        if not self.speech_text:\n",
    "            with self.status_output:\n",
    "                clear_output()\n",
    "                print(\"❌ Please generate a speech first before creating audio.\")\n",
    "            return\n",
    "            \n",
    "        with self.status_output:\n",
    "            clear_output()\n",
    "            print(\"🔊 Generating audio... This may take a moment.\")\n",
    "            \n",
    "        with self.audio_output:\n",
    "            clear_output()\n",
    "            try:\n",
    "                # Generate a filename from speech metadata\n",
    "                topic_clean = self.generator._sanitize_filename(self.speech_metadata[\"topic\"])\n",
    "                voice_id = self.voice_dropdown.value\n",
    "                voice_name = voice_id.split('_')[1]  # Extract part of voice ID for filename\n",
    "                \n",
    "                audio_filename = f\"{topic_clean}_{voice_name}.wav\"\n",
    "                \n",
    "                # Generate audio\n",
    "                self.audio_path = self.generator.generate_speech_audio(\n",
    "                    text=self.speech_text,\n",
    "                    voice=voice_id,\n",
    "                    output_filename=audio_filename\n",
    "                )\n",
    "                \n",
    "                # Show audio player\n",
    "                audio = Audio(self.audio_path)\n",
    "                display(HTML(\"<h3>Speech Audio Preview</h3>\"))\n",
    "                display(audio)\n",
    "                \n",
    "                # Show download link\n",
    "                display(HTML(f'<a href=\"{self.audio_path}\" download>Download Audio File</a>'))\n",
    "                \n",
    "                with self.status_output:\n",
    "                    clear_output()\n",
    "                    print(f\"✅ Audio generated successfully and saved to: {self.audio_path}\")\n",
    "                    print(\"Use the audio player above to preview or download the file.\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                with self.status_output:\n",
    "                    clear_output()\n",
    "                    print(f\"❌ Error generating audio: {str(e)}\")\n",
    "                print(f\"Error details: {str(e)}\")\n",
    "    \n",
    "    def _on_clear_button_click(self, button):\n",
    "        \"\"\"Handle clear button click.\"\"\"\n",
    "        with self.output:\n",
    "            clear_output()\n",
    "        with self.audio_output:\n",
    "            clear_output()\n",
    "        with self.status_output:\n",
    "            clear_output()\n",
    "            print(\"Output cleared. Ready for a new speech generation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd8fae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Create and run the application\n",
    "def run_speech_generator():\n",
    "    \"\"\"Initialize and run the speech generator application.\"\"\"\n",
    "    try:\n",
    "        # Try to load API key from a file, but don't fail if not found\n",
    "        api_key_path = os.path.join(os.path.expanduser(\"~\"), \".groq_api_key.json\")\n",
    "        if os.path.exists(api_key_path):\n",
    "            generator = SpeechGenerator(api_key_path)\n",
    "        else:\n",
    "            generator = SpeechGenerator()\n",
    "            \n",
    "        # Create and display the UI\n",
    "        ui = SpeechGeneratorUI(generator)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing the Speech Generator: {str(e)}\")\n",
    "        print(\"Please make sure you have all required packages installed:\")\n",
    "        print(\"pip install groq ipywidgets transformers torchaudio torch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a6417f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ddd532ea7c4456a0972555dcbff808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee33835032d4c68885c0bd6612456e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/585M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Run the application when this script is executed directly\n",
    "if __name__ == \"__main__\" or 'ipykernel' in sys.modules:\n",
    "    run_speech_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c9dc10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
