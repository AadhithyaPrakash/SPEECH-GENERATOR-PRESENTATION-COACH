{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Inlustro\\t5speechenv\\Lib\\site-packages\\transformers\\utils\\hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HOME\"] = \"F:/huggingface\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"F:/huggingface/datasets\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"F:/huggingface/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_dataset = load_dataset(\"ted_talks_iwslt\", \"nl_en_2016\", split=\"train\", trust_remote_code=True)\n",
    "\n",
    "subs_dataset = load_dataset(\"open_subtitles\", \"en-hi\", split=\"train\", trust_remote_code=True)\n",
    "\n",
    "book_dataset = load_dataset(\"bookcorpus\", split=\"train\", trust_remote_code=True)\n",
    "\n",
    "cnn_dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"train\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_ted(example):\n",
    "    return {\n",
    "        \"input\": \"Generate a professional speech about: \" + example[\"translation\"][\"en\"][:60],\n",
    "        \"target\": example[\"translation\"][\"en\"]\n",
    "    }\n",
    "\n",
    "def format_subs(example):\n",
    "    return {\n",
    "        \"input\": \"Generate a funny speech about: \" + example[\"translation\"][\"en\"][:60],\n",
    "        \"target\": example[\"translation\"][\"en\"]\n",
    "    }\n",
    "\n",
    "def format_book(example):\n",
    "    return {\n",
    "        \"input\": \"Generate a structured speech from: \" + example[\"text\"][:60],\n",
    "        \"target\": example[\"text\"]\n",
    "    }\n",
    "\n",
    "def format_cnn(example):\n",
    "    return {\n",
    "        \"input\": \"Generate a formal speech about: \" + example[\"article\"][:60],\n",
    "        \"target\": example[\"article\"]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_formatted = ted_dataset.map(format_ted)\n",
    "subs_formatted = subs_dataset.map(format_subs)\n",
    "book_formatted = book_dataset.map(format_book)\n",
    "cnn_formatted = cnn_dataset.map(format_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep input and target\n",
    "ted_formatted = ted_formatted.remove_columns([col for col in ted_formatted.column_names if col not in [\"input\", \"target\"]])\n",
    "subs_formatted = subs_formatted.remove_columns([col for col in subs_formatted.column_names if col not in [\"input\", \"target\"]])\n",
    "book_formatted = book_formatted.remove_columns([col for col in book_formatted.column_names if col not in [\"input\", \"target\"]])\n",
    "cnn_formatted = cnn_formatted.remove_columns([col for col in cnn_formatted.column_names if col not in [\"input\", \"target\"]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 0 columns: ['input', 'target']\n",
      "Dataset 0 features: {'input': Value(dtype='string', id=None), 'target': Value(dtype='string', id=None)}\n",
      "Dataset 1 columns: ['input', 'target']\n",
      "Dataset 1 features: {'input': Value(dtype='string', id=None), 'target': Value(dtype='string', id=None)}\n",
      "Dataset 2 columns: ['input', 'target']\n",
      "Dataset 2 features: {'input': Value(dtype='string', id=None), 'target': Value(dtype='string', id=None)}\n",
      "Dataset 3 columns: ['input', 'target']\n",
      "Dataset 3 features: {'input': Value(dtype='string', id=None), 'target': Value(dtype='string', id=None)}\n"
     ]
    }
   ],
   "source": [
    "combined_dataset = concatenate_datasets([ted_formatted, subs_formatted, book_formatted, cnn_formatted])\n",
    "for i, ds in enumerate(datasets_to_combine):\n",
    "    print(f\"Dataset {i} columns:\", ds.column_names)\n",
    "    print(f\"Dataset {i} features:\", ds.features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input', 'target'],\n",
      "    num_rows: 74388209\n",
      "})\n",
      "{'input': \"Generate a professional speech about: We don't have to live in a world where 99 percent of rapists\", 'target': 'We don\\'t have to live in a world where 99 percent of rapists get away with it, says TED Fellow Jessica Ladd. With Callisto, a new platform for college students to confidentially report sexual assault, Ladd is helping survivors get the support and justice they deserve while respecting their privacy concerns. \"We can create a world where there\\'s a real deterrent to violating the rights of another human being,\" she says.'}\n"
     ]
    }
   ],
   "source": [
    "print(combined_dataset)\n",
    "print(combined_dataset[0])  # Just to see a sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283c5b125cad45cc8f85eef94d13faad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a4bed653424e43941f5e16b5c8b4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c72eb5a17e314e2892217a95fed7b6c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    inputs = tokenizer(batch[\"input\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    targets = tokenizer(batch[\"target\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]  # Set the target input_ids as labels\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e549acf2bca8449caf7241d7c97d9d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/74388209 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = combined_dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenized_datasets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./t5-large-speech-gen\",\n",
    "    per_device_train_batch_size=1,                # ðŸ§  Safe for RTX 3050\n",
    "    gradient_accumulation_steps=4,                # Simulates batch size 4\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=3e-4,\n",
    "    save_total_limit=2,\n",
    "    save_steps=1000,\n",
    "    logging_steps=500,\n",
    "    evaluation_strategy=\"no\",\n",
    "    fp16=True,                                    # âœ… Mixed Precision\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save_pretrained(\"t5-large-speech-gen-model\")\n",
    "tokenizer.save_pretrained(\"t5-large-speech-gen-model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-large-speech-gen-model\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-large-speech-gen-model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Generate a funny speech about artificial intelligence in college life\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "output_ids = model.generate(inputs, max_length=200, num_beams=4, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "print(\"\\nGenerated Speech:\\n\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input', 'target'],\n",
      "    num_rows: 74388209\n",
      "})\n",
      "{'input': \"Generate a professional speech about: We don't have to live in a world where 99 percent of rapists\", 'target': 'We don\\'t have to live in a world where 99 percent of rapists get away with it, says TED Fellow Jessica Ladd. With Callisto, a new platform for college students to confidentially report sexual assault, Ladd is helping survivors get the support and justice they deserve while respecting their privacy concerns. \"We can create a world where there\\'s a real deterrent to violating the rights of another human being,\" she says.'}\n"
     ]
    }
   ],
   "source": [
    "print(combined_dataset)\n",
    "print(combined_dataset[0])  # Just to see a sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input', 'target'],\n",
      "    num_rows: 74388209\n",
      "})\n",
      "{'input': \"Generate a professional speech about: We don't have to live in a world where 99 percent of rapists\", 'target': 'We don\\'t have to live in a world where 99 percent of rapists get away with it, says TED Fellow Jessica Ladd. With Callisto, a new platform for college students to confidentially report sexual assault, Ladd is helping survivors get the support and justice they deserve while respecting their privacy concerns. \"We can create a world where there\\'s a real deterrent to violating the rights of another human being,\" she says.'}\n"
     ]
    }
   ],
   "source": [
    "print(combined_dataset)\n",
    "print(combined_dataset[0])  # Just to see a sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input', 'target'],\n",
      "    num_rows: 74388209\n",
      "})\n",
      "{'input': \"Generate a professional speech about: We don't have to live in a world where 99 percent of rapists\", 'target': 'We don\\'t have to live in a world where 99 percent of rapists get away with it, says TED Fellow Jessica Ladd. With Callisto, a new platform for college students to confidentially report sexual assault, Ladd is helping survivors get the support and justice they deserve while respecting their privacy concerns. \"We can create a world where there\\'s a real deterrent to violating the rights of another human being,\" she says.'}\n"
     ]
    }
   ],
   "source": [
    "print(combined_dataset)\n",
    "print(combined_dataset[0])  # Just to see a sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input', 'target'],\n",
      "    num_rows: 74388209\n",
      "})\n",
      "{'input': \"Generate a professional speech about: We don't have to live in a world where 99 percent of rapists\", 'target': 'We don\\'t have to live in a world where 99 percent of rapists get away with it, says TED Fellow Jessica Ladd. With Callisto, a new platform for college students to confidentially report sexual assault, Ladd is helping survivors get the support and justice they deserve while respecting their privacy concerns. \"We can create a world where there\\'s a real deterrent to violating the rights of another human being,\" she says.'}\n"
     ]
    }
   ],
   "source": [
    "print(combined_dataset)\n",
    "print(combined_dataset[0])  # Just to see a sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input', 'target'],\n",
      "    num_rows: 74388209\n",
      "})\n",
      "{'input': \"Generate a professional speech about: We don't have to live in a world where 99 percent of rapists\", 'target': 'We don\\'t have to live in a world where 99 percent of rapists get away with it, says TED Fellow Jessica Ladd. With Callisto, a new platform for college students to confidentially report sexual assault, Ladd is helping survivors get the support and justice they deserve while respecting their privacy concerns. \"We can create a world where there\\'s a real deterrent to violating the rights of another human being,\" she says.'}\n"
     ]
    }
   ],
   "source": [
    "print(combined_dataset)\n",
    "print(combined_dataset[0])  # Just to see a sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input', 'target'],\n",
      "    num_rows: 74388209\n",
      "})\n",
      "{'input': \"Generate a professional speech about: We don't have to live in a world where 99 percent of rapists\", 'target': 'We don\\'t have to live in a world where 99 percent of rapists get away with it, says TED Fellow Jessica Ladd. With Callisto, a new platform for college students to confidentially report sexual assault, Ladd is helping survivors get the support and justice they deserve while respecting their privacy concerns. \"We can create a world where there\\'s a real deterrent to violating the rights of another human being,\" she says.'}\n"
     ]
    }
   ],
   "source": [
    "print(combined_dataset)\n",
    "print(combined_dataset[0])  # Just to see a sample\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t5speechenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
